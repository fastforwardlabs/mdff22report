## Considerations

So far we have discussed and experimented with approaches for dealing with concept drift when the ground truth of the newly available data instances isn’t readily available. While we covered methods that are model agnostic and truly unsupervised, detecting concept drift in practice is not a straightforward task. As noted by the researchers of [Learning under Concept Drift: A Review](https://arxiv.org/pdf/2004.05785.pdf), handling concept drift is generally coupled with other ML problems. In this section, we cover a few of these overlapping issues along with some considerations when designing a drift detection strategy.

### Ethics

It’s impossible to design a machine learning system knowing everything about the domain upfront. As we’ve seen, concept drift occurs by default as a result of static models operating in dynamic environments. And therefore, deployed models will naturally have unintended consequences. For this reason, it's imperative that teams plan for uncertainty post-deployment and have robust monitoring and detection processes established to understand when something has gone wrong and take corrective action.

However, the act of monitoring a feature or metric just to “check the box” is not enough. Blindly optimizing and maintaining a poorly selected set of metrics results in far from optimal outcomes. This is because metric optimization often leads to manipulation, gaming, and a focus on short-term quantities at the expense of longer-term concerns. When developing a post-production strategy, it’s important to use a slate of metrics to gain a fuller picture of a model's true impact, combine metrics with qualitative accounts, and involve a range of stakeholders including those who will be impacted downstream by the model’s decisions.^[[Reliance on Metrics is a Fundamental Challenge for AI](https://arxiv.org/pdf/2002.08512.pdf)] Planning for and monitoring a model's impact on a wider set of concerns than just predictive performance adds an additional layer of complexity to the already difficult task of production machine learning. But it's a requirement, not an option.

### Other Prediction Tasks

Up until now, all of the methods discussed for inferring drift have been in the context of binary classification. But how can these approaches be extended to other tasks like multiclass classification and regression? At the core of our approaches, we are simply using a trained model to produce a distribution of uncertainty and then comparing that distribution between reference and detection windows. Therefore, we can apply this same idea to other tasks by reformulating our definition of uncertainty. In the binary classification task, uncertainty exists as the difference between the two class probabilities. In a multiclass classification task, uncertainty could be defined as the difference between the top two class probabilities. Similarly for regression tasks, the notion of uncertainty could take the form of absolute error of each prediction.

### Class Imbalance

The common issue of class-imbalance is exacerbated when it comes to drift detection. Class imbalance occurs when the proportion of data instances belonging to each class varies, causing certain classes to be underrepresented. It is usually the underrepresented classes in such situations that end up having higher misclassifications. Detecting drift between populations with imbalanced classes is complicated, and becomes more challenging when the data between windows cannot be stored due to memory issues. As such, approaches that cater to both concept drift and class imbalance in data streams are relatively less studied.^[[Incremental learning imbalanced data streams with concept drift: The dynamic updated ensemble algorithm](https://www.sciencedirect.com/science/article/abs/pii/S095070512030126X)] That said, CDS (Concept Drift with SMOTE (Synthetic Minority class Oversampling Technique)) is one of the more recent batch-based incremental learning algorithms that strategically uses the minority class data to tackle this problem.^[[Incremental Learning of Concept Drift from Streaming Imbalanced Data](https://ieeexplore.ieee.org/document/6235959)]

Another related problem that is largely under-explored is dealing with multi-label classification where a particular data instance could be associated with one or more labels. For example, a news article may have overlapping classes like “politics”, “environment” and “energy”. Multi-label data streams contain independent relationships for each label where each concept is likely to have its own drift pattern that may drift asynchronously from its peers. In addition, label proportions may not be consistent across detection windows. To deal with these challenges a notable approach^[[Dealing with Concept Drift and Class Imbalance in Multi-Label Stream Classification](https://www.ijcai.org/Proceedings/11/Papers/266.pdf)] associates each label with two fixed size instance-windows, one for positive and the other for negative examples for the training data. The size of the positive window is a user-specified parameter, and it should be large enough to learn an accurate model, but small enough to reduce the probability of drift within the window. The number of negative examples in the negative window is determined based on the ratio of the number of positive examples to another user-specified parameter －distribution ratio. This parameter plays the role of balancing the distribution of positive and negative examples in the union of the two windows and ranges typically from 0.3 to 0.7. The approach allows it to oversample the positive and undersample the negative examples for all labels. They further build and use k-nearest neighbor (k-NN) classifiers to determine the label of an unlabeled test instance. Normally a k-NN classifier outputs a class label based on whether the probability of it belonging to the positive class is >= 0.5. This default behavior is an improper choice when it comes to imbalanced classes and the authors instead propose a batch specific thresholding approach to combat that.

### Active Learning

Active learning is a set of machine learning techniques that reduces the number of labeled examples required to train a model. In settings where the labeled examples are available only initially or are scarce, active learning approaches utilize these labels to build an initial model, and then uses this model to request labels for data points from a human that the model finds hard to predict on. A scenario where the unlabeled data stream is drifting could pose additional challenges. For instance, active learning strategies that request labels for the most uncertain instances would typically concentrate around the decision boundary. Changes that occur further from the boundary may be missed, and models may fail to adapt. Some solutions to effectively tackle such challenges include learning strategies that are guided by drift detection to save labeling costs for difﬁcult and evolving instances.^[[Active Learning With Drifting Streaming Data](https://ieeexplore.ieee.org/document/6414645)]^[[Combining active learning with concept drift detection for data stream mining](https://www.researchgate.net/publication/330629277_Combining_active_learning_with_concept_drift_detection_for_data_stream_mining)]

### Semi-supervised Learning

Semi-supervised and transductive learning techniques leverage both labeled and unlabeled examples to learn more generalized models when limited labeled data is available for training. Because this technique naturally learns from unlabeled data, it may be assumed that models of this type can easily track drifting concepts. However, that’s not the case because with concept drift, training data and test data are generated from different underlying distributions. Due to this unique learning paradigm, there have been many new developments specific to semi-supervised and transductive learning in the presence of concept drift. For instance, the weight estimation algorithm (an ensemble-based classifier approach^[[Semi-supervised Learning in Nonstationary Environments](http://users.rowan.edu/~polikar/RESEARCH/PUBLICATIONS/ijcnn11.pdf)]) uses unlabeled test data along with a set of mixture models to adjust classifier voting weights. The approach helps detect gradual or incremental drifts. There is also the COMPOSE (COMPacted Object Sample Extraction) approach that can handle multi-class data, including the scenario of new classes or new subpopulations for gradual drift detection.^[[COMPOSE: A Semisupervised Learning Framework for Initially Labeled Nonstationary Streaming Data](https://www.researchgate.net/publication/260354243_COMPOSE_A_Semisupervised_Learning_Framework_for_Initially_Labeled_Nonstationary_Streaming_Data)])

### Big Data

Data in big data streaming environments is often generated at a fast rate, in large quantities, and is highly volatile - a scenario prime for drifting concepts. Due to the high throughput nature, it may not always be feasible to capture, store, and process all the data. This complication has led to the development of scalable and parallel algorithmic implementations that only need one pass through the data, and thus train and adapt to concept drifts in real-time scenarios. For instance, the Online MapReduce Drift Detection Method (OMR-DDM)^[[Parallel Concept Drift Detection with Online Map-Reduce](https://ieeexplore.ieee.org/document/6406468)]) detects drift by the use of the error rate of a collection of classifiers executed concurrently. Approaches like Micro-Cluster Nearest Neighbor (MC-NN)^[[Scalable real-time classification of data streams with concept drift](https://www.sciencedirect.com/science/article/pii/S0167739X17304685)]) do not need data to reside in memory, are processed incrementally and adapt to concept drifts by monitoring classification error.